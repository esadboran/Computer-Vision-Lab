{"cells":[{"cell_type":"markdown","metadata":{"id":"PhUHRZPfqr7G"},"source":["# Homework 1\n","\n","*Evolved from Stanford Vision Lab. in the url \" https://github.com/StanfordVL/CS131_release/blob/master/fall_2021/hw2_release/hw2.ipynb \"*\n","\n","*This notebook includes both coding and written questions. Please hand in this notebook file with all the outputs and your answers to the written questions.*\n","\n","This assignment covers Sobel edge detector, Canny edge detector and Hough transform."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCY2ISM8qr7J"},"outputs":[],"source":["# Setup\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from time import time\n","from skimage import io\n","\n","from __future__ import print_function\n","\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (15.0, 12.0) # set default size of plots\n","plt.rcParams['image.interpolation'] = 'nearest'\n","plt.rcParams['image.cmap'] = 'gray'\n","\n","# for auto-reloading extenrnal modules\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","source":["##Part 1: Edge Detectors (50 Points)\n","\n","In this part, you are going to implement Sobel and Canny edge detectors. In addition, you will compare the detectors visually."],"metadata":{"id":"ok8yItCAriNS"}},{"cell_type":"markdown","source":["### 1.1 Sobel Edge Detector (15 Points)\n","In this part, you are going to implement Sobel edge detector. The Sobel edge detection algorithm can be broken down in to three steps:\n","\n","1. Convolving with Sobel-x filter\n","2. Convolving with Sobel-y filter\n","3. Finding gradients\n"],"metadata":{"id":"tATFtDNezwrH"}},{"cell_type":"markdown","source":["#### 1.1.1 Convolving with Sobel-x filter (5 Points)\n","\n","We first compute the sobel-x filter multiplying 1D Gaussian filter and x derivative. The equation can be given below:\n","\n","$$\\begin{align}\n","    s_x &= \\begin{bmatrix}\n","           1 \\\\\n","           2 \\\\\n","           1\n","         \\end{bmatrix} * \\begin{bmatrix} 1 & 0 & -1\n","         \\end{bmatrix}\n","  \\end{align}$$\n","\n","\n","Implement **`conv`** and **`sobel_x`**."],"metadata":{"id":"ZPOvMHLHD5hN"}},{"cell_type":"code","source":["def conv(image, kernel):\n","    \"\"\" An implementation of convolution filter.\n","    This function uses element-wise multiplication and np.sum()\n","    to efficiently compute weighted sum of neighborhood at each\n","    pixel.\n","    Args:\n","        image: numpy array of shape (Hi, Wi).\n","        kernel: numpy array of shape (Hk, Wk).\n","    Returns:\n","        out: numpy array of shape (Hi, Wi).\n","    \"\"\"\n","    Hi, Wi = image.shape\n","    Hk, Wk = kernel.shape\n","    out = np.zeros((Hi, Wi))\n","\n","    # For this assignment, we will use edge values to pad the images.\n","    # Zero padding will make derivatives at the image boundary very big,\n","    # whereas we want to ignore the edges at the boundary.\n","    pad_width0 = Hk // 2\n","    pad_width1 = Wk // 2\n","    pad_width = ((pad_width0,pad_width0),(pad_width1,pad_width1))\n","    padded = np.pad(image, pad_width, mode='edge')\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return out"],"metadata":{"id":"XlGdjvjLtYyk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sobel_x():\n","    \"\"\" Implementation of Sobel-x filter.\n","    This function follows the sobel-x formula,\n","    and creates a kernel matrix.\n","    Hints:\n","    - Use gaussian 1d kernel.\n","    Args:\n","    Returns:\n","        kernel: numpy array of shape (3, 3).\n","    \"\"\"\n","    s_x = np.zeros((3, 3))\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","    \n","    return s_x"],"metadata":{"id":"Qt8Bx_1KHb85"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load image\n","img = io.imread('iguana.png', as_gray=True)\n","\n","# Create sobel-x filter\n","kernel_x = sobel_x()\n","\n","# Convolve the image with kernel\n","G_x = conv(img, kernel_x)\n","\n","plt.subplot(1,2,1)\n","plt.imshow(img)\n","plt.title('Original image')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(G_x)\n","plt.title('Gradient x image')\n","plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"SNR6rhkqN6O4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.1.2 Convolving with Sobel-y filter (5 Points)\n","\n","We first compute the sobel-y filter multiplying y derivative and 1D Gaussian filter. The equation can be given below:\n","\n","$$\\begin{align}\n","    s_x &= \\begin{bmatrix}\n","           -1 \\\\\n","           0 \\\\\n","           -1\n","         \\end{bmatrix} * \\begin{bmatrix} 1 & 2 & 1\n","         \\end{bmatrix}\n","  \\end{align}$$\n","\n","\n","Implement **`sobel_y`**."],"metadata":{"id":"RIDds2a8PUvB"}},{"cell_type":"code","source":["def sobel_y():\n","    \"\"\" Implementation of Sobel-y filter.\n","    This function follows the sobel-y formula,\n","    and creates a kernel matrix.\n","    Hints:\n","    - Use gaussian 1d kernel.\n","    Args:\n","    Returns:\n","        kernel: numpy array of shape (3, 3).\n","    \"\"\"\n","    s_y = np.zeros((3, 3))\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","    \n","    return s_y"],"metadata":{"id":"fER7g33yQJ3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create sobel-y filter\n","kernel_y = sobel_y()\n","\n","# Convolve the image with kernel\n","G_y = conv(img, kernel_y)\n","\n","plt.subplot(1,2,1)\n","plt.imshow(img)\n","plt.title('Original image')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(G_y)\n","plt.title('Gradient y image')\n","plt.axis('off')\n","\n","plt.show()"],"metadata":{"id":"qhMJYL18QYdJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.1.3 Finding Gradient Magnitude (5 Points)\n","\n","G_x denotes right direction that increases where G_y denotes down direction that increases. At each point in the image, the resulting gradient can be obtined to give the gradient magnitude and direction below:\n","\n","$$G = \\sqrt{G_{x}^{2} + G_{y}^{2}} \\\\ \\theta = arctan2(\\frac{G_y}{G_x})$$\n","\n","Implement **`grad`**."],"metadata":{"id":"9Np_4g1FQkVJ"}},{"cell_type":"code","source":["def grad(G_x, G_y):\n","    \"\"\" Returns gradient magnitude and direction of input image sobel gradients.\n","    Args:\n","        img: Gradient x and gradient y. Numpy array of shape (H, W).\n","    Returns:\n","        G: Magnitude of sobel gradient at each pixel in img.\n","            Numpy array of shape (H, W).\n","        theta: Direction(in degrees, 0 <= theta < 360) of sobel gradient\n","            at each pixel in img. Numpy array of shape (H, W).\n","    Hints:\n","        - Use np.sqrt and np.arctan2 to calculate square root and arctan\n","    \"\"\"\n","    G = np.zeros(G_x.shape)\n","    theta = np.zeros(G_x.shape)\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return G, theta"],"metadata":{"id":"Kzm6_eHrTRfb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["G, theta = grad(G_x, G_y)\n","\n","if not np.all(G >= 0):\n","    print('Magnitude of gradients should be non-negative.')\n","    \n","if not np.all((theta >= 0) * (theta < 360)):\n","    print('Direction of gradients should be in range 0 <= theta < 360')\n","\n","plt.imshow(G)\n","plt.title('Gradient magnitude')\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"b9KXjYvXUTO-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.1.4 Sobel Edge Detector\n","\n","Implement sobel using the functions you have implemented so far."],"metadata":{"id":"rEydpp_LU7Vt"}},{"cell_type":"code","source":["def sobel(img):\n","    \"\"\" Implement sobel edge detector by calling functions above.\n","    Args:\n","        img: binary image of shape (H, W).\n","    Returns:\n","        edge: numpy array of shape(H, W).\n","    \"\"\"\n","    H, W = img.shape\n","    edge = np.zeros((H, W), dtype=np.bool)\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return edge"],"metadata":{"id":"swItbggPUqLi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"abyT4fGgqr7O"},"source":["### 1.2 Canny Edge Detector (25 points)\n","In this part, you are going to implement Canny edge detector. The Canny edge detection algorithm can be broken down in to five steps:\n","1. Smoothing\n","2. Finding gradients\n","3. Non-maximum suppression\n","4. Double thresholding\n","5. Edge tracking by hysterisis"]},{"cell_type":"markdown","metadata":{"id":"ACutmtqEqr7Q"},"source":["#### 1.2.1 Smoothing (5 points)\n","##### Implementation (2.5 points)\n","We first smooth the input image by convolving it with a Gaussian kernel. The equation for a Gaussian kernel of size $(2k+1)\\times(2k+1)$ is given by:\n","\n","$$h_{ij}=\\frac{1}{2\\pi\\sigma^2}\\exp{\\Bigl(-\\frac{(i-k)^2+(j-k)^2}{2\\sigma^2}\\Bigr)}, 0\\leq i,j < 2k+1$$\n","\n","Implement **`gaussian_kernel`** and run the code below."]},{"cell_type":"code","source":["def gaussian_kernel(size, sigma):\n","    \"\"\" Implementation of Gaussian Kernel.\n","    This function follows the gaussian kernel formula,\n","    and creates a kernel matrix.\n","    Hints:\n","    - Use np.pi and np.exp to compute pi and exp.\n","    Args:\n","        size: int of the size of output matrix.\n","        sigma: float of sigma to calculate kernel.\n","    Returns:\n","        kernel: numpy array of shape (size, size).\n","    \"\"\"\n","\n","    kernel = np.zeros((size, size))\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return kernel"],"metadata":{"id":"cjSYg15Ssyrq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"zYs_aaMUqr7R"},"outputs":[],"source":["# Define 3x3 Gaussian kernel with std = 1\n","kernel = gaussian_kernel(3, 1)\n","kernel_test = np.array(\n","    [[ 0.05854983, 0.09653235, 0.05854983],\n","     [ 0.09653235, 0.15915494, 0.09653235],\n","     [ 0.05854983, 0.09653235, 0.05854983]]\n",")\n","\n","# Test Gaussian kernel\n","if not np.allclose(kernel, kernel_test):\n","    print('Incorrect values! Please check your implementation.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBiamg6bqr7S"},"outputs":[],"source":["# Test with different kernel_size and sigma\n","kernel_size = 5\n","sigma = 1.4\n","\n","# Load image\n","img = io.imread('iguana.png', as_grey=True)\n","\n","# Define 5x5 Gaussian kernel with std = sigma\n","kernel = gaussian_kernel(kernel_size, sigma)\n","\n","# Convolve image with kernel to achieve smoothed effect\n","smoothed = conv(img, kernel)\n","\n","plt.subplot(1,2,1)\n","plt.imshow(img)\n","plt.title('Original image')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(smoothed)\n","plt.title('Smoothed image')\n","plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"2nr29kQ9qr7U"},"source":["##### Question (2.5 points)\n","What is the effect of the kernel_size and sigma?"]},{"cell_type":"markdown","metadata":{"id":"agxuOkWkqr7U"},"source":["**Your Answer:** Write your solution in this markdown cell."]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"w1UzfQjtqr7V"},"source":["#### 1.2.2 Finding gradients (5 points)\n","The gradient of a 2D scalar function $I:\\mathbb{R}^2\\rightarrow{\\mathbb{R}}$ in Cartesian coordinate is defined by:\n","\n","$$\\nabla{I(x,y)}=\\bigl[\\frac{\\partial{I}}{\\partial{x}},\\frac{\\partial{I}}{\\partial{y}}\\bigr],$$\n","\n","where\n","\n","$$\n","\\frac{\\partial{I(x,y)}}{\\partial{x}}=\\lim_{\\Delta{x}\\to{0}}\\frac{I(x+\\Delta{x},y)-I(x,y)}{\\Delta{x}} \\\\\n","\\frac{\\partial{I(x,y)}}{\\partial{y}}=\\lim_{\\Delta{y}\\to{0}}\\frac{I(x,y+\\Delta{y})-I(x,y)}{\\Delta{y}}.\n","$$\n","\n","In case of images, we can approximate the partial derivatives by taking differences at one pixel intervals:\n","\n","$$\n","\\frac{\\partial{I(x,y)}}{\\partial{x}}\\approx{\\frac{I(x+1,y)-I(x-1,y)}{2}} \\\\\n","\\frac{\\partial{I(x,y)}}{\\partial{y}}\\approx{\\frac{I(x,y+1)-I(x,y-1)}{2}}\n","$$\n","\n","Note that the partial derivatives can be computed by convolving the image $I$ with some appropriate kernels $D_x$ and $D_y$:\n","\n","$$\n","\\frac{\\partial{I}}{\\partial{x}}\\approx{I*D_x}=G_x \\\\\n","\\frac{\\partial{I}}{\\partial{y}}\\approx{I*D_y}=G_y\n","$$"]},{"cell_type":"markdown","metadata":{"id":"4jSsBPBsqr7X"},"source":["##### Implementation (2 points)\n","Find the kernels $D_x$ and $D_y$ and implement **`partial_x`** and **`partial_y`** using `conv`.\n","\n","*-Hint: Remeber that convolution flips the kernel.*"]},{"cell_type":"code","source":["def partial_x(img):\n","    \"\"\" Computes partial x-derivative of input img.\n","    Hints:\n","        - You may use the conv function in defined in this file.\n","    Args:\n","        img: numpy array of shape (H, W).\n","    Returns:\n","        out: x-derivative image.\n","    \"\"\"\n","\n","    out = None\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return out"],"metadata":{"id":"jiaXX7eit5TE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def partial_y(img):\n","    \"\"\" Computes partial y-derivative of input img.\n","    Hints:\n","        - You may use the conv function in defined in this file.\n","    Args:\n","        img: numpy array of shape (H, W).\n","    Returns:\n","        out: y-derivative image.\n","    \"\"\"\n","\n","    out = None\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return out"],"metadata":{"id":"9-3v8KzMt9tk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"OZ9NElYeqr7X"},"outputs":[],"source":["# Test input\n","I = np.array(\n","    [[0, 0, 0],\n","     [0, 1, 0],\n","     [0, 0, 0]]\n",")\n","\n","# Expected outputs\n","I_x_test = np.array(\n","    [[ 0, 0, 0],\n","     [ 0.5, 0, -0.5],\n","     [ 0, 0, 0]]\n",")\n","\n","I_y_test = np.array(\n","    [[ 0, 0.5, 0],\n","     [ 0, 0, 0],\n","     [ 0, -0.5, 0]]\n",")\n","\n","# Compute partial derivatives\n","I_x = partial_x(I)\n","I_y = partial_y(I)\n","\n","# Test correctness of partial_x and partial_y\n","if not np.all(I_x == I_x_test):\n","    print('partial_x incorrect')\n","    \n","if not np.all(I_y == I_y_test):\n","    print('partial_y incorrect')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eArVYi_qr7Y"},"outputs":[],"source":["# Compute partial derivatives of smoothed image\n","Gx = partial_x(smoothed)\n","Gy = partial_y(smoothed)\n","\n","plt.subplot(1,2,1)\n","plt.imshow(Gx)\n","plt.title('Derivative in x direction')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(Gy)\n","plt.title('Derivative in y direction')\n","plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ImPkNErUqr7Z"},"source":["##### Question (1 points)\n","What is the reason for performing smoothing prior to computing the gradients?"]},{"cell_type":"markdown","metadata":{"id":"pH2GjmNJqr7a"},"source":["**Your Answer:** Write your solution in this markdown cell."]},{"cell_type":"markdown","metadata":{"id":"9kUT2nEdqr7a"},"source":["##### Implementation (2 points)\n","Now, we can compute the magnitude and direction of gradient with the two partial derivatives:\n","\n","$$\n","G = \\sqrt{G_{x}^{2}+G_{y}^{2}} \\\\\n","\\Theta = arctan\\bigl(\\frac{G_{y}}{G_{x}}\\bigr)\n","$$\n","\n","Implement **`gradient`** which takes in an image and outputs $G$ and $\\Theta$.\n","\n","*-Hint: Use np.arctan2 to compute $\\Theta$.*"]},{"cell_type":"code","source":["def gradient(img):\n","    \"\"\" Returns gradient magnitude and direction of input img.\n","    Args:\n","        img: Grayscale image. Numpy array of shape (H, W).\n","    Returns:\n","        G: Magnitude of gradient at each pixel in img.\n","            Numpy array of shape (H, W).\n","        theta: Direction(in degrees, 0 <= theta < 360) of gradient\n","            at each pixel in img. Numpy array of shape (H, W).\n","    Hints:\n","        - Use np.sqrt and np.arctan2 to calculate square root and arctan\n","    \"\"\"\n","    G = np.zeros(img.shape)\n","    theta = np.zeros(img.shape)\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return G, theta"],"metadata":{"id":"ygoOzwXtvJjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLUFUE4qqr7b"},"outputs":[],"source":["G, theta = gradient(smoothed)\n","\n","if not np.all(G >= 0):\n","    print('Magnitude of gradients should be non-negative.')\n","    \n","if not np.all((theta >= 0) * (theta < 360)):\n","    print('Direction of gradients should be in range 0 <= theta < 360')\n","\n","plt.imshow(G)\n","plt.title('Gradient magnitude')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"znIYwwFiqr7b"},"source":["#### 1.2.3 Non-maximum suppression (5 points)\n","You should be able to note that the edges extracted from the gradient of the smoothed image is quite thick and blurry. The purpose of this step is to convert the \"blurred\" edges into \"sharp\" edges. Basically, this is done by preserving all local maxima in the gradient image and discarding everything else. The algorithm is for each pixel (x,y) in the gradient image:\n","1. Round the gradient direction $\\Theta[y,x]$ to the nearest 45 degrees, corresponding to the use of an 8-connected neighbourhood.\n","\n","2. Compare the edge strength of the current pixel with the edge strength of the pixel in the positive and negative gradient direction. For example, if the gradient direction is south (theta=90), compare with the pixels to the north and south.\n","\n","3. If the edge strength of the current pixel is the largest; preserve the value of the edge strength. If not, suppress (i.e. remove) the value.\n","\n","Implement **`non_maximum_suppression`**."]},{"cell_type":"code","source":["def non_maximum_suppression(G, theta):\n","    \"\"\" Performs non-maximum suppression.\n","    This function performs non-maximum suppression along the direction\n","    of gradient (theta) on the gradient magnitude image (G).\n","    Args:\n","        G: gradient magnitude image with shape of (H, W).\n","        theta: direction of gradients with shape of (H, W).\n","    Returns:\n","        out: non-maxima suppressed image.\n","    \"\"\"\n","    H, W = G.shape\n","    out = np.zeros((H, W))\n","\n","    # Round the gradient direction to the nearest 45 degrees\n","    theta = np.floor((theta + 22.5) / 45) * 45\n","    theta = (theta % 360.0).astype(np.int32)\n","\n","    #print(G)\n","    ### BEGIN YOUR CODE\n","    pass\n","    ### END YOUR CODE\n","\n","    return out"],"metadata":{"id":"NkwVndDJvYOQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0zRixugTqr7c"},"outputs":[],"source":["# Test input\n","g = np.array(\n","    [[0.4, 0.5, 0.6],\n","     [0.3, 0.5, 0.7],\n","     [0.4, 0.5, 0.6]]\n",")\n","\n","# Print out non-maximum suppressed output\n","# varying theta\n","for angle in range(0, 180, 45):\n","    print('Thetas:', angle)\n","    t = np.ones((3, 3)) * angle # Initialize theta\n","    print(non_maximum_suppression(g, t))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e138ckg-qr7d"},"outputs":[],"source":["nms = non_maximum_suppression(G, theta)\n","plt.imshow(nms)\n","plt.title('Non-maximum suppressed')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"O5nwynGCqr7d"},"source":["#### 1.2.4 Double Thresholding (5 points)\n","\n","The edge-pixels remaining after the non-maximum suppression step are (still) marked with their strength pixel-by-pixel. Many of these will probably be true edges in the image, but some may be caused by noise or color variations, for instance, due to rough surfaces. The simplest way to discern between these would be to use a threshold, so that only edges stronger that a certain value would be preserved. The Canny edge detection algorithm uses double thresholding. Edge pixels stronger than the high threshold are marked as strong; edge pixels weaker than the low threshold are suppressed and edge pixels between the two thresholds are marked as weak.\n","\n","Implement **`double_thresholding`**."]},{"cell_type":"code","source":["def double_thresholding(img, high, low):\n","    \"\"\"\n","    Args:\n","        img: numpy array of shape (H, W) representing NMS edge response.\n","        high: high threshold(float) for strong edges.\n","        low: low threshold(float) for weak edges.\n","    Returns:\n","        strong_edges: Boolean array representing strong edges.\n","            Strong edeges are the pixels with the values greater than\n","            the higher threshold.\n","        weak_edges: Boolean array representing weak edges.\n","            Weak edges are the pixels with the values smaller or equal to the\n","            higher threshold and greater than the lower threshold.\n","    \"\"\"\n","\n","    strong_edges = np.zeros(img.shape, dtype=np.bool)\n","    weak_edges = np.zeros(img.shape, dtype=np.bool)\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return strong_edges, weak_edges"],"metadata":{"id":"_zlkjZzPxr0q"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1nJbU0yqr7e"},"outputs":[],"source":["low_threshold = 0.02\n","high_threshold = 0.03\n","\n","strong_edges, weak_edges = double_thresholding(nms, high_threshold, low_threshold)\n","assert(np.sum(strong_edges & weak_edges) == 0)\n","\n","edges=strong_edges * 1.0 + weak_edges * 0.5\n","\n","plt.subplot(1,2,1)\n","plt.imshow(strong_edges)\n","plt.title('Strong Edges')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(edges)\n","plt.title('Strong+Weak Edges')\n","plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"vF-7WOjIqr7f"},"source":["#### 1.2.5 Edge tracking (5 points)\n","\n","Strong edges are interpreted as “certain edges”, and can immediately be included in the final edge image. Weak edges are included if and only if they are connected to strong edges. The logic is of course that noise and other small variations are unlikely to result in a strong edge (with proper adjustment of the threshold levels). Thus strong edges will (almost) only be due to true edges in the original image. The weak edges can either be due to true edges or noise/color variations. The latter type will probably be distributed in dependently of edges on the entire image, and thus only a small amount will be located adjacent to strong edges. Weak edges due to true edges are much more likely to be connected directly to strong edges.\n","\n","Implement **`link_edges`**."]},{"cell_type":"code","source":["def get_neighbors(y, x, H, W):\n","    \"\"\" Return indices of valid neighbors of (y, x).\n","    Return indices of all the valid neighbors of (y, x) in an array of\n","    shape (H, W). An index (i, j) of a valid neighbor should satisfy\n","    the following:\n","        1. i >= 0 and i < H\n","        2. j >= 0 and j < W\n","        3. (i, j) != (y, x)\n","    Args:\n","        y, x: location of the pixel.\n","        H, W: size of the image.\n","    Returns:\n","        neighbors: list of indices of neighboring pixels [(i, j)].\n","    \"\"\"\n","    neighbors = []\n","\n","    for i in (y-1, y, y+1):\n","        for j in (x-1, x, x+1):\n","            if i >= 0 and i < H and j >= 0 and j < W:\n","                if (i == y and j == x):\n","                    continue\n","                neighbors.append((i, j))\n","\n","    return neighbors"],"metadata":{"id":"b-wDwr3i4x31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def link_edges(strong_edges, weak_edges):\n","    \"\"\" Find weak edges connected to strong edges and link them.\n","    Iterate over each pixel in strong_edges and perform breadth first\n","    search across the connected pixels in weak_edges to link them.\n","    Here we consider a pixel (a, b) is connected to a pixel (c, d)\n","    if (a, b) is one of the eight neighboring pixels of (c, d).\n","    Args:\n","        strong_edges: binary image of shape (H, W).\n","        weak_edges: binary image of shape (H, W).\n","    \n","    Returns:\n","        edges: numpy boolean array of shape(H, W).\n","    \"\"\"\n","\n","    H, W = strong_edges.shape\n","    indices = np.stack(np.nonzero(strong_edges)).T\n","    edges = np.zeros((H, W), dtype=np.bool)\n","\n","    # Make new instances of arguments to leave the original\n","    # references intact\n","    weak_edges = np.copy(weak_edges)\n","    edges = np.copy(strong_edges)\n","\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return edges"],"metadata":{"id":"Qo23XFOZx5fh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmG0p6AUqr7g"},"outputs":[],"source":["test_strong = np.array(\n","    [[1, 0, 0, 0],\n","     [0, 0, 0, 0],\n","     [0, 0, 0, 0],\n","     [0, 0, 0, 1]]\n",")\n","\n","test_weak = np.array(\n","    [[0, 0, 0, 1],\n","     [0, 1, 0, 0],\n","     [1, 0, 0, 0],\n","     [0, 0, 1, 0]]\n",")\n","\n","test_linked = link_edges(test_strong, test_weak)\n","\n","plt.subplot(1, 3, 1)\n","plt.imshow(test_strong)\n","plt.title('Strong edges')\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(test_weak)\n","plt.title('Weak edges')\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(test_linked)\n","plt.title('Linked edges')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SkBYbPD4qr7h"},"outputs":[],"source":["edges = link_edges(strong_edges, weak_edges)\n","\n","plt.imshow(edges)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3kzWzrLwqr7h"},"source":["### 1.6 Canny edge detector\n","Implement **`canny`** using the functions you have implemented so far. Test edge detector with different parameters.\n","\n","Here is an example of the output:\n","\n","<img src=\"iguana_edges.png\" width=\"400\">"]},{"cell_type":"code","source":["def canny(img, kernel_size=5, sigma=1.4, high=20, low=15):\n","    \"\"\" Implement canny edge detector by calling functions above.\n","    Args:\n","        img: binary image of shape (H, W).\n","        kernel_size: int of size for kernel matrix.\n","        sigma: float for calculating kernel.\n","        high: high threshold for strong edges.\n","        low: low threashold for weak edges.\n","    Returns:\n","        edge: numpy array of shape(H, W).\n","    \"\"\"\n","    H, W = img.shape\n","    edge = np.zeros((H, W), dtype=np.bool)\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return edge"],"metadata":{"id":"plxM9ZfQyoGf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PZeMIDwqr7i"},"outputs":[],"source":["# Load image\n","img = io.imread('iguana.png', as_grey=True)\n","\n","# Run Canny edge detector\n","edges = canny(img, kernel_size=5, sigma=1.4, high=0.03, low=0.02)\n","print (edges.shape)\n","plt.imshow(edges)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"xlZH_AeDqr7i"},"source":["#### 1.2.7 Question (10 points)\n","\n","<img src=\"1.7a.png\" width=\"400\">\n","\n","**(a)** Suppose that the Canny edge detector successfully detects an edge in an image. The edge (see the figure above) is then rotated by θ, where the relationship between a point on the original edge $(x, y)$ and a point on the rotated edge $(x', y')$ is defined as\n","\n","$$\n","x'=x\\cos{\\theta}\\\\\n","y'=x\\sin{\\theta}\n","$$\n","\n","Will the rotated edge be detected using the same Canny edge detector? Provide either a mathematical proof or a counter example.\n","\n","*-Hint: The detection of an edge by the Canny edge detector depends only on the magnitude of its derivative. The derivative at point (x, y) is determined by its components along the x and y directions. Think about how these magnitudes have changed because of the rotation.*"]},{"cell_type":"markdown","metadata":{"id":"vc77v64Iqr7j"},"source":["**Your Answer:** Write your solution in this markdown cell."]},{"cell_type":"markdown","metadata":{"id":"C1llx9tOqr7j"},"source":["**(b)** After running the Canny edge detector on an image, you notice that long edges are broken into short segments separated by gaps. In addition, some spurious edges appear. For each of the two thresholds (low and high) used in hysteresis thresholding, explain how you would adjust the threshold (up or down) to address both problems. Assume that a setting exists for the two thresholds that produces the desired result. Briefly explain your answer."]},{"cell_type":"markdown","metadata":{"id":"KOsCmskmqr7k"},"source":["**Your Answer:** Write your solution in this markdown cell."]},{"cell_type":"markdown","metadata":{"id":"H_QO86QEqr7k"},"source":["### Extra Credit: Optimizing Edge Detector\n","One way of evaluating an edge detector is to compare detected edges with manually specified ground truth edges. Here, we use precision, recall and F1 score as evaluation metrics. We provide you 40 images of objects with ground truth edge annotations. Run the code below to compute precision, recall and F1 score over the entire set of images. Then, tweak the parameters of the Canny edge detector to get as high F1 score as possible. You should be able to achieve F1 score higher than 0.31 by carefully setting the parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"sgAdQsZlqr7k"},"outputs":[],"source":["from os import listdir\n","from itertools import product\n","\n","# Define parameters to test\n","sigmas = []\n","highs = []\n","lows = []\n","\n","for sigma, high, low in product(sigmas, highs, lows):\n","\n","    print(\"sigma={}, high={}, low={}\".format(sigma, high, low))\n","    n_detected = 0.0\n","    n_gt = 0.0\n","    n_correct = 0.0\n","\n","    for img_file in listdir('images/objects'):\n","        img = io.imread('images/objects/'+img_file, as_grey=True)\n","        gt = io.imread('images/gt/'+img_file+'.gtf.pgm', as_grey=True)\n","\n","        mask = (gt != 5) # 'don't' care region\n","        gt = (gt == 0) # binary image of GT edges\n","\n","        edges = canny(img, kernel_size=5, sigma=sigma, high=high, low=low)\n","        edges = edges * mask\n","\n","        n_detected += np.sum(edges)\n","        n_gt += np.sum(gt)\n","        n_correct += np.sum(edges * gt)\n","\n","    p_total = n_correct / n_detected\n","    r_total = n_correct / n_gt\n","    f1 = 2 * (p_total * r_total) / (p_total + r_total)\n","    print('Total precision={:.4f}, Total recall={:.4f}'.format(p_total, r_total))\n","    print('F1 score={:.4f}'.format(f1))"]},{"cell_type":"markdown","metadata":{"id":"25WugRQDqr7l"},"source":["## Part2: Lane Detection (50 points)\n","\n","In this section we will implement a simple lane detection application using Sobel edge detector, Canny edge detector and Hough transform.\n","Here are some example images of how your final lane detector will look like.\n","<img src=\"lane1.png\" width=\"400\">\n","<img src=\"lane2.png\" width=\"400\">\n","\n","The algorithm can broken down into the following steps:\n","1. Detect edges using the edge detector.\n","2. Extract the edges in the region of interest (a triangle covering the bottom corners and the center of the image).\n","3. Run Hough transform to detect lanes.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f_VJcVgDqr7l"},"source":["### 2.1 Edge detection\n","Lanes on the roads are usually thin and long lines with bright colors. Our edge detection algorithm by itself should be able to find the lanes pretty well. Run the code cell below to load the example image and detect edges from the image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yffwIbwTqr7m"},"outputs":[],"source":["# Load image\n","img = io.imread('00000.jpg', as_grey=True)\n","\n","# Run Sobel edge detector\n","#edges_sobel = sobel(img)\n","\n","# Run Canny edge detector\n","edges = canny(img, kernel_size=5, sigma=1.4, high=0.03, low=0.02)\n","\n","plt.subplot(211)\n","plt.imshow(img)\n","plt.axis('off')\n","plt.title('Input Image')\n","\n","plt.subplot(212)\n","plt.imshow(edges)\n","plt.axis('off')\n","plt.title('Edges')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"BLJsW4uaqr7m"},"source":["### 2.2 Extracting region of interest (ROI)\n","We can see that the Canny edge detector could find the edges of the lanes. However, we can also see that there are edges of other objects that we are not interested in. Given the position and orientation of the camera, we know that the lanes will be located in the lower half of the image. The code below defines a binary mask for the ROI and extract the edges within the region."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZfaQzI5Wqr7m"},"outputs":[],"source":["H, W = img.shape\n","\n","# Generate mask for ROI (Region of Interest)\n","mask = np.zeros((H, W))\n","for i in range(H):\n","    for j in range(W):\n","        if i > (H / W) * j and i > -(H / W) * j + H:\n","            mask[i, j] = 1\n","\n","# Extract edges in ROI\n","roi = edges * mask\n","\n","plt.subplot(1,2,1)\n","plt.imshow(mask)\n","plt.title('Mask')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.imshow(roi)\n","plt.title('Edges in ROI')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"_7jHivLHqr7n"},"source":["### 2.3 Fitting lines using Hough transform (50 points)\n","The output from the edge detector is still a collection of connected points. However, it would be more natural to represent a lane as a line parameterized as $y = ax + b$, with a slope $a$ and y-intercept $b$. We will use Hough transform to find parameterized lines that represent the detected edges.\n","\n","In general, a straight line $y = ax + b$ can be represented as a point $(a, b)$ in the parameter space. However, this cannot represent vertical lines as the slope parameter will be unbounded. Alternatively, we parameterize a line using $\\theta\\in{[-\\pi, \\pi]}$ and $\\rho\\in{\\mathbb{R}}$ as follows:\n","\n","$$\n","\\rho = x\\cdot{cos\\theta} + y\\cdot{sin\\theta}\n","$$\n","\n","Using this parameterization, we can map everypoint in $xy$-space to a sine-like line in $\\theta\\rho$-space (or Hough space). We then accumulate the parameterized points in the Hough space and choose points (in Hough space) with highest accumulated values. A point in Hough space then can be transformed back into a line in $xy$-space.\n","\n","*See [notes](http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/HoughTrans_lines_09.pdf) on Hough transform.*\n","\n","Implement **`hough_transform`**."]},{"cell_type":"code","source":["def hough_transform(img):\n","    \"\"\" Transform points in the input image into Hough space.\n","    Use the parameterization:\n","        rho = x * cos(theta) + y * sin(theta)\n","    to transform a point (x,y) to a sine-like function in Hough space.\n","    Args:\n","        img: binary image of shape (H, W).\n","        \n","    Returns:\n","        accumulator: numpy array of shape (m, n).\n","        rhos: numpy array of shape (m, ).\n","        thetas: numpy array of shape (n, ).\n","    \"\"\"\n","    # Set rho and theta ranges\n","    W, H = img.shape\n","    diag_len = int(np.ceil(np.sqrt(W * W + H * H)))\n","    rhos = np.linspace(-diag_len, diag_len, diag_len * 2 + 1)\n","    thetas = np.deg2rad(np.arange(-90.0, 90.0))\n","\n","    # Cache some reusable values\n","    cos_t = np.cos(thetas)\n","    sin_t = np.sin(thetas)\n","    num_thetas = len(thetas)\n","\n","    # Initialize accumulator in the Hough space\n","    accumulator = np.zeros((2 * diag_len + 1, num_thetas), dtype=np.uint64)\n","    ys, xs = np.nonzero(img)\n","\n","    # Transform each point (x, y) in image\n","    # Find rho corresponding to values in thetas\n","    # and increment the accumulator in the corresponding coordiate.\n","    ### YOUR CODE HERE\n","    pass\n","    ### END YOUR CODE\n","\n","    return accumulator, rhos, thetas"],"metadata":{"id":"FDSBB7X63WWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fL35ZLRnqr7n"},"outputs":[],"source":["# Perform Hough transform on the ROI\n","acc, rhos, thetas = hough_transform(roi)\n","\n","# Coordinates for right lane\n","xs_right = []\n","ys_right = []\n","\n","# Coordinates for left lane\n","xs_left = []\n","ys_left = []\n","\n","for i in range(20):\n","    idx = np.argmax(acc)\n","    r_idx = idx // acc.shape[1]\n","    t_idx = idx % acc.shape[1]\n","    acc[r_idx, t_idx] = 0 # Zero out the max value in accumulator\n","\n","    rho = rhos[r_idx]\n","    theta = thetas[t_idx]\n","    \n","    # Transform a point in Hough space to a line in xy-space.\n","    a = - (np.cos(theta)/np.sin(theta)) # slope of the line\n","    b = (rho/np.sin(theta)) # y-intersect of the line\n","\n","    # Break if both right and left lanes are detected\n","    if xs_right and xs_left:\n","        break\n","    \n","    if a < 0: # Left lane\n","        if xs_left:\n","            continue\n","        xs = xs_left\n","        ys = ys_left\n","    else: # Right Lane\n","        if xs_right:\n","            continue\n","        xs = xs_right\n","        ys = ys_right\n","\n","    for x in range(img.shape[1]):\n","        y = a * x + b\n","        if y > img.shape[0] * 0.6 and y < img.shape[0]:\n","            xs.append(x)\n","            ys.append(int(round(y)))\n","\n","plt.imshow(img)\n","plt.plot(xs_left, ys_left, linewidth=5.0)\n","plt.plot(xs_right, ys_right, linewidth=5.0)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"cW_JutOSqr7p"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}